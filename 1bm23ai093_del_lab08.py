# -*- coding: utf-8 -*-
"""1BM23AI093_DEL_LAB08.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xKyK2O1jVkh05BP3V6FYdqylfeLWL15Q
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding,LSTM, SimpleRNN, Dense

max_features=10000
maxlen=200
(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_features)

word_index=imdb.get_word_index()
index_to_word={idx:word for word, idx in word_index.items()}

print("IMDb dataset sample:")
for i in range(5):
  words=[index_to_word.get(idx,'?') for idx in x_train[i]]
  review_text=''.join(words)
  print("Review",i+1,":",review_text)
  print("Sentiment:",y_train[i])
  print()

x_train=pad_sequences(x_train,maxlen=maxlen)
x_test=pad_sequences(x_test,maxlen=maxlen)

embedding_dim=50
model=Sequential()
model.add(Embedding(max_features,embedding_dim,input_length=maxlen))
model.add(SimpleRNN(units=64,dropout=0.2,recurrent_dropout=0.2))
model.add(Dense(units=1,activation='sigmoid'))
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
history=model.fit(x_train,y_train,epochs=5,batch_size=128,validation_split=0.2)
loss,accuracy=model.evaluate(x_test,y_test)
print('Test accuracy:',accuracy)

def predict_sentiment(text):
  word_to_index=imdb.get_word_index()
  words=text.split()
  sequence=[word_to_index[word]if word in word_to_index and word_to_index[word]<max_features else 0 for word in words]
  sequence=pad_sequences([sequence],maxlen=maxlen)
  prediction=model.predict(sequence)[0][0]
  return prediction

positive_text="This movie was fantastic, I loved every moment of it!"
negative_text="I couldnt stand this movie, it was terrible"
print("positive text sentiment:", predict_sentiment(positive_text))
print("negative text sentiment:", predict_sentiment(negative_text))

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'],label='Training Accuracy')
plt.plot(history.history['val_accuracy'],label='validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
plt.plot(history.history['loss'],label='Training loss')
plt.plot(history.history['val_loss'],label='validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

