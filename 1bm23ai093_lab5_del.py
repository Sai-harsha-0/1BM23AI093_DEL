# -*- coding: utf-8 -*-
"""1BM23AI093_LAB5_DEL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hp_pMhDLzQDGYz26A0JCViBsbvdiAKsq
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

mnist=keras.datasets.mnist
(X_train,y_train),(X_test,y_test)=mnist.load_data()
X_train,X_test=X_train/255.0,X_test/255.0
y_train_parity=np.array([np.sum(np.array(list(map(int,str(y)))))%2 for y in y_train])
y_test_parity=np.array([np.sum(np.array(list(map(int,str(y)))))%2 for y in y_test])

import matplotlib.pyplot as plt
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(X_train[i],cmap=plt.cm.binary)
    plt.xlabel(y_train[i])
plt.show()

inputs=keras.Input(shape=(28,28))
x=layers.Flatten()(inputs)
x=layers.Dense(128,activation='relu')(x)
outputs=layers.Dense(10,activation='softmax')(x)
outputs_parity=layers.Dense(1,activation='sigmoid')(x)
model=keras.Model(inputs=inputs,outputs=[outputs,outputs_parity])
model.compile(optimizer='adam',loss=['sparse_categorical_crossentropy','binary_crossentropy'],metrics=['accuracy', 'accuracy'])
early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)
history=model.fit(X_train,[y_train,y_train_parity],epochs=20,validation_split=0.2,callbacks=[early_stopping])
early_stopping_epoch=np.argmin(history.history['val_loss'])+1
print("\n\nEarly stopping occured at epoch:",early_stopping_epoch)
plt.plot(history.history['loss'],label='Training loss')
plt.plot(history.history['val_loss'],label='Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and validation loss')
plt.axvline(x=early_stopping_epoch,color='r',linestyle='--',label='Early stopping')
plt.legend()
plt.show()

|